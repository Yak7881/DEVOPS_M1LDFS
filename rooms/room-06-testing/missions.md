# ğŸ¯ Missions â€” Room 06 (Testing)

4 missions, 3 points chacune. Fais-les dans l'ordre.

---

## Mission 1 â€” Ã‰crire un test simple en pseudo-code (3 pts)

**Objectif :** Ã‰crire un test pour une fonction.

**Contexte :** Une fonction `multiply(a, b)` multiplie deux nombres.

**Ã€ faire :** Ã‰cris en pseudo-code (ou vrai code si tu prÃ©fÃ¨res) un test qui :
1. Appelle `multiply(3, 4)`
2. VÃ©rifie que le rÃ©sultat est `12`

**Exemple de rÃ©ponse :**
```text
Test : test_multiply
  rÃ©sultat = multiply(3, 4)
  assertion : rÃ©sultat == 12
```

**Validation :** Tu as compris la structure : appeler la fonction, puis vÃ©rifier le rÃ©sultat.

---

## Mission 2 â€” Identifier 3 choses Ã  tester dans un formulaire de login (3 pts)

**Objectif :** RÃ©flÃ©chir Ã  ce qu'il faut tester.

**Contexte :** Un formulaire de login a : email, mot de passe, bouton "Se connecter".

**Ã€ faire :** Liste 3 choses qu'on pourrait tester (en 1 phrase chacune).

**Exemples :**
- VÃ©rifier qu'un email valide est acceptÃ©
- VÃ©rifier qu'un email invalide est refusÃ©
- VÃ©rifier qu'un mot de passe vide est refusÃ©

**Validation :** Tu as listÃ© 3 cas de test pertinents.

---

## Mission 3 â€” Lire une sortie de test et dÃ©terminer si Ã§a passe ou Ã©choue (3 pts)

**Objectif :** Comprendre la sortie d'un test runner.

**Contexte :** Voici une sortie de test (exemple) :

```text
test_add ... OK
test_subtract ... FAIL (AssertionError: expected 2, got 3)
test_multiply ... OK

Ran 3 tests in 0.02s
FAILED (failures=1)
```

**Questions :**
1. Combien de tests ont Ã©tÃ© exÃ©cutÃ©s ?
2. Combien ont rÃ©ussi ? Combien ont Ã©chouÃ© ?
3. Quel test a Ã©chouÃ© et pourquoi ?

**Validation :** Tu as identifiÃ© le test en Ã©chec et la raison (rÃ©sultat attendu 2, obtenu 3).

---

## Mission 4 â€” Trouver oÃ¹ les tests sont exÃ©cutÃ©s dans le pipeline du repo (3 pts)

**Objectif :** Savoir oÃ¹ les tests s'intÃ¨grent dans le CI.

**Ã‰tapes :**

1. Ouvre le pipeline [.github/workflows/ci.yml](../../.github/workflows/ci.yml)
2. Cherche si des tests sont exÃ©cutÃ©s explicitement
3. Si ce repo n'a pas de tests dans le pipeline, Ã©cris : "Ce pipeline ne lance pas de tests pour l'instant. Dans un projet typique, on ajouterait une Ã©tape du type `run: npm test` ou `run: pytest`."

**Validation :** Tu as compris que le pipeline actuel vÃ©rifie la structure et que les tests peuvent Ãªtre ajoutÃ©s comme Ã©tape.

---

## ğŸ“Š Score missions

| Mission | Points |
|---------|--------|
| 1 | 3 |
| 2 | 3 |
| 3 | 3 |
| 4 | 3 |
| **Total** | **12** |

---

> âœ… **TerminÃ© ?** Passe au [checkpoint](./checkpoint.md).
